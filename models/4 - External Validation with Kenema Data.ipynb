{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - External Validation with Kenema Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from scipy import interp\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Use the RWinOut instead of rpy2.ipython to get output on windows \n",
    "# https://bitbucket.org/rpy2/rpy2/issues/125/set_writeconsole-not-working-on-windows\n",
    "# https://github.com/vitorcurtis/RWinOut\n",
    "#%load_ext RWinOut\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load import_notebook.py\n",
    "# Infraestructure to import a Jupyter notebook\n",
    "# http://jupyter-notebook.readthedocs.io/en/latest/examples/Notebook/Importing%20Notebooks.html\n",
    "\n",
    "import io, os, sys, types\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "def find_notebook(fullname, path=None):\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "\n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        \n",
    "\n",
    "class NotebookLoader(object):\n",
    "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "\n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "\n",
    "        print (\"importing Jupyter notebook from %s\" % path)\n",
    "\n",
    "        # load the notebook object\n",
    "        with io.open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = read(f, 4)\n",
    "\n",
    "\n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "\n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "\n",
    "        try:\n",
    "            for cell in nb.cells:\n",
    "                if cell.cell_type == 'code':\n",
    "                    # transform the input to executable Python\n",
    "                    code = self.shell.input_transformer_manager.transform_cell(cell.source)\n",
    "                    # run the code in themodule\n",
    "                    exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod\n",
    "    \n",
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "\n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "\n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "\n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]\n",
    "\n",
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from LogRegUtils.ipynb\n"
     ]
    }
   ],
   "source": [
    "from LogRegUtils import LogRegModel\n",
    "from LogRegUtils import caldis, calibration_table, calibration, calibration2\n",
    "from LogRegUtils import create_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_model = 2\n",
    "\n",
    "risk_threshold = 0.5\n",
    "\n",
    "make_plots = False\n",
    "\n",
    "if sel_model == 1:\n",
    "    model_name = 'all-minimal'\n",
    "elif sel_model == 2:\n",
    "    model_name = 'all-clinical-only'\n",
    "elif sel_model == 3:\n",
    "    model_name = 'all-parsimonious'    \n",
    "elif sel_model == 4:\n",
    "    model_name = 'all-parsimonious-notemp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kenema_data_file = '../../kenema/mirador/data_normalized.csv'\n",
    "kenema_data = pd.read_csv(kenema_data_file, na_values=\"\\\\N\")\n",
    "\n",
    "var_dict = { \n",
    "  'Disposition':'OUT',\n",
    "  'PatientAge':'AGE', \n",
    "  'cycletime':'CT', \n",
    "  'FeverTemperature':'TEMP', \n",
    "  'Fever':'FEVER',\n",
    "  'Jaundice':'JAUN', \n",
    "  'Bleeding':'BLEED', \n",
    "  'Breathlessness':'BREATH', \n",
    "  'SwallowingProblems':'STHROAT', \n",
    "  'AstheniaWeakness':'WEAK',\n",
    "  'reftime':'DONSET',\n",
    "  'Diarrhoea':'DIARR'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     OUT   AGE  TEMP  JAUN  BLEED  BREATH  STHROAT  WEAK  DIARR\n",
      "20   1.0  38.0  36.7     0    0.0     0.0      0.0   0.0    1.0\n",
      "21   1.0  43.0  37.1     0    0.0     0.0      0.0   1.0    1.0\n",
      "23   1.0  37.0  38.4     0    0.0     0.0      0.0   1.0    0.0\n",
      "26   1.0  45.0  36.4     0    0.0     0.0      1.0   1.0    1.0\n",
      "28   1.0  35.0  38.3     0    0.0     0.0      1.0   1.0    1.0\n",
      "29   1.0  22.0  36.2     0    0.0     0.0      0.0   1.0    1.0\n",
      "30   1.0  50.0  38.4     0    0.0     1.0      1.0   1.0    0.0\n",
      "31   1.0  14.0  37.0     0    0.0     0.0      0.0   0.0    0.0\n",
      "32   1.0  45.0  39.9     0    0.0     1.0      0.0   1.0    0.0\n",
      "37   1.0  60.0  37.4     0    0.0     0.0      1.0   1.0    0.0\n",
      "38   1.0  35.0  36.1     0    0.0     0.0      0.0   0.0    1.0\n",
      "39   0.0  50.0  36.2     0    0.0     0.0      0.0   0.0    1.0\n",
      "42   0.0  45.0  36.4     0    0.0     0.0      0.0   0.0    0.0\n",
      "46   1.0  63.0  37.4     0    0.0     0.0      0.0   0.0    0.0\n",
      "48   0.0  36.0  36.3     0    0.0     0.0      0.0   0.0    0.0\n",
      "53   1.0  30.0  38.3     0    0.0     1.0      0.0   1.0    1.0\n",
      "57   0.0  38.0  36.3     0    0.0     0.0      0.0   0.0    0.0\n",
      "58   0.0  10.0  36.0     0    0.0     0.0      0.0   0.0    0.0\n",
      "59   1.0  60.0  36.0     0    0.0     0.0      0.0   1.0    1.0\n",
      "61   1.0  40.0  36.5     0    0.0     0.0      1.0   1.0    1.0\n",
      "63   1.0   6.0  36.6     0    0.0     0.0      0.0   0.0    0.0\n",
      "64   1.0   2.0  36.6     0    0.0     0.0      0.0   0.0    0.0\n",
      "65   1.0  40.0  37.2     0    0.0     0.0      0.0   0.0    0.0\n",
      "67   0.0   4.0  32.2     0    0.0     0.0      0.0   0.0    0.0\n",
      "68   1.0   4.0  36.6     0    0.0     0.0      0.0   0.0    0.0\n",
      "69   1.0  40.0  39.2     0    0.0     0.0      1.0   1.0    0.0\n",
      "70   0.0  35.0  37.6     0    0.0     1.0      1.0   0.0    0.0\n",
      "73   1.0  42.0  37.5     0    0.0     0.0      0.0   0.0    0.0\n",
      "74   1.0  40.0  37.6     0    0.0     0.0      0.0   0.0    0.0\n",
      "76   1.0  30.0  37.8     0    0.0     1.0      0.0   0.0    0.0\n",
      "80   1.0  12.0  38.0     0    1.0     0.0      1.0   1.0    1.0\n",
      "83   1.0  30.0  38.6     0    0.0     0.0      0.0   1.0    0.0\n",
      "84   1.0  35.0  36.8     0    0.0     0.0      0.0   0.0    0.0\n",
      "85   1.0  60.0  37.0     0    0.0     0.0      1.0   1.0    1.0\n",
      "86   1.0  45.0  37.3     0    0.0     1.0      0.0   1.0    0.0\n",
      "89   1.0  45.0  38.0     0    0.0     0.0      0.0   0.0    0.0\n",
      "90   1.0   5.0  39.5     0    0.0     0.0      1.0   1.0    1.0\n",
      "91   1.0  40.0  37.5     0    0.0     0.0      0.0   1.0    1.0\n",
      "92   1.0  40.0  37.4     0    0.0     1.0      1.0   1.0    1.0\n",
      "93   1.0  49.0  37.5     0    0.0     0.0      0.0   1.0    1.0\n",
      "95   1.0  14.0  38.0     0    0.0     0.0      0.0   1.0    1.0\n",
      "99   0.0  32.0  36.0     0    0.0     0.0      0.0   1.0    0.0\n",
      "100  1.0  52.0  39.2     0    0.0     0.0      0.0   0.0    0.0\n",
      "101  1.0  40.0  36.4     0    0.0     0.0      1.0   1.0    1.0\n"
     ]
    }
   ],
   "source": [
    "model_params = os.path.join(model_name, 'model.csv')\n",
    "model = LogRegModel(model_params)\n",
    "\n",
    "predictors = model.getPredictors()\n",
    "\n",
    "variables = ['OUT'] + [var_dict[var] for var in predictors]\n",
    "\n",
    "test_data = kenema_data[variables]\n",
    "complete_data = test_data.dropna()\n",
    "print(complete_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on complete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases : 44\n",
      "Number of deaths: 36\n",
      "CFR             : 81.82\n",
      "\n",
      "Measures of performance\n",
      "AUC           : 0.72\n",
      "Brier         : 0.22\n",
      "Accuracy      : 0.59\n",
      "Sensitivity   : 0.56\n",
      "Specificity   : 0.75\n"
     ]
    }
   ],
   "source": [
    "x = complete_data[complete_data.columns[1:]].values\n",
    "ytrue = [int(v) for v in complete_data[complete_data.columns[0]].values]\n",
    "probs = model.predict(x)\n",
    "ypred = [int(risk_threshold < p) for p in probs]\n",
    "\n",
    "auc = roc_auc_score(ytrue, probs)\n",
    "fpr, tpr, thresholds = roc_curve(ytrue, probs) \n",
    "brier = brier_score_loss(ytrue, probs)\n",
    "cal, dis = caldis(ytrue, probs)\n",
    "acc = accuracy_score(ytrue, ypred)\n",
    "precision, recall, f1score, support = precision_recall_fscore_support(ytrue, ypred)\n",
    "\n",
    "P = N = 0\n",
    "TP = TN = 0\n",
    "FP = FN = 0\n",
    "for i in range(len(ytrue)):\n",
    "    if ytrue[i] == 1:\n",
    "        P += 1\n",
    "        if ypred[i] == 1: TP += 1\n",
    "        else: FN += 1\n",
    "    else:\n",
    "        N += 1\n",
    "        if ypred[i] == 0: TN += 1\n",
    "        else: FP += 1\n",
    "            \n",
    "sens = float(TP)/P\n",
    "spec = float(TN)/N\n",
    "\n",
    "# Positive and Negative Predictive Values\n",
    "# https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values\n",
    "ppv = float(TP) / (TP + FP)\n",
    "npv = float(TN) / (TN + FN)\n",
    "        \n",
    "# Likelihood ratios\n",
    "# https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing\n",
    "lr_pos = sens / (1 - spec) if spec < 1 else np.inf\n",
    "lr_neg = (1 - sens) / spec if 0 < spec else np.inf\n",
    "    \n",
    "# print \"True outcomes:\", ytrue\n",
    "# print \"Prediction   :\", ypred\n",
    "cfr = 100 * (float(np.sum(ytrue)) / len(ytrue))\n",
    "print(\"Number of cases :\", len(ytrue))\n",
    "print(\"Number of deaths:\", np.sum(ytrue)) \n",
    "print(\"CFR             : %0.2f\" % cfr)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Measures of performance\") \n",
    "print(\"AUC           : %0.2f\" % auc) \n",
    "print(\"Brier         : %0.2f\" % brier) \n",
    "# print(\"Calibration   :\", cal) \n",
    "# print(\"Discrimination:\", dis) \n",
    "print(\"Accuracy      : %0.2f\" % acc) \n",
    "print(\"Sensitivity   : %0.2f\" % sens) \n",
    "print(\"Specificity   : %0.2f\" % spec) \n",
    "# print(\"PPV           :\", ppv) \n",
    "# print(\"NPV           :\", npv) \n",
    "# print(\"LR+           :\", lr_pos) \n",
    "# print(\"LR-           :\", lr_neg) \n",
    "\n",
    "# print(\"Precision (live)  :\", precision[0],\" (specificity for die)\")\n",
    "# print(\"Precision (die)   :\", precision[1],\" (specificity for live)\")\n",
    "# print(\"Sensitivity (live):\", recall[0])\n",
    "# print(\"Sensitivity (die) :\", recall[1]) \n",
    "# print(\"F1 (live)         :\", f1score[0]) \n",
    "# print(\"F1 (die)          :\", f1score[1])\n",
    "\n",
    "with open(os.path.join(model_name, 'kenema-validation.txt'), 'w') as of:\n",
    "    of.write(\"Measures of performance\\n\")\n",
    "    of.write(\"AUC           : %0.2f\\n\" % auc)\n",
    "    of.write(\"Brier         : %0.2f\\n\" % brier)\n",
    "#     of.write(\"Calibration   : \" + str(cal) + \"\\n\")\n",
    "#     of.write(\"Discrimination: \" + str(dis) + \"\\n\")\n",
    "    of.write(\"Accuracy      : %0.2f\\n\" % acc)\n",
    "    of.write(\"Sensitivity   : %0.2f\\n\" % sens)\n",
    "    of.write(\"Specificity   : %0.2f\\n\" % spec)\n",
    "#     of.write(\"PPV           : \" + str(ppv) + \"\\n\")\n",
    "#     of.write(\"NPV           : \" + str(npv) + \"\\n\")\n",
    "#     of.write(\"LR+           : \" + str(lr_pos) + \"\\n\")\n",
    "#     of.write(\"LR-           : \" + str(lr_neg) + \"\\n\")    \n",
    "    \n",
    "#     of.write(\"Precision (live)  : \" + str(precision[0]) + \" (specificity for die)\\n\")\n",
    "#     of.write(\"Precision (die)   : \" + str(precision[1]) + \" (specificity for live)\\n\")\n",
    "#     of.write(\"Sensitivity (live): \" + str(recall[0]) + \"\\n\")\n",
    "#     of.write(\"Sensitivity (die) : \" + str(recall[1]) + \"\\n\")\n",
    "#     of.write(\"F1 (live)         : \" + str(f1score[0]) + \"\\n\")\n",
    "#     of.write(\"F1 (die)          : \" + str(f1score[1]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if make_plots:\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.xlim([-0.1, 1.1])\n",
    "    plt.ylim([-0.1, 1.1])\n",
    "    plt.plot([0, 1], [0, 1], 'k--', c='grey')\n",
    "    plt.plot(fpr, tpr, color='black')\n",
    "    plt.xlabel('1 - Specificity')\n",
    "    plt.ylabel('Sensitivity')\n",
    "    fig.savefig(os.path.join(model_name, 'kenema-roc-complete.pdf'))\n",
    "\n",
    "    cal_table = calibration_table(ytrue, probs, 10)\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot([0.05, 0.95], [0.05, 0.95], '-', c='grey', linewidth=0.5, zorder=1)\n",
    "    plt.xlim([-0.1, 1.1])\n",
    "    plt.ylim([-0.1, 1.1])\n",
    "    plt.xlabel('Predicted Risk')\n",
    "    plt.ylabel('Observed Risk')\n",
    "    x = cal_table['pred_prob']\n",
    "    y = cal_table['true_prob']\n",
    "    # f = interp1d(x, y, kind='cubic')\n",
    "    # xnew = np.linspace(min(x), max(x), num=50, endpoint=True)    \n",
    "    # plt.plot(xnew, f(xnew))\n",
    "    plt.plot(x, y, color='black')\n",
    "    fig.savefig(os.path.join(model_name, 'kenema-cal-complete.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on imputed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source data\n",
    "test_data_folder = 'imp-kenema'\n",
    "test_data_file = os.path.join(model_name, 'src_kenema.csv')\n",
    "\n",
    "num_imp = 100   # Number of multiple imputations\n",
    "\n",
    "# Load imputation files for selected model, if any\n",
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join, exists    \n",
    "imp_data_folder = os.path.join(model_name, test_data_folder)\n",
    "if not os.path.exists(imp_data_folder):\n",
    "    os.makedirs(imp_data_folder)\n",
    "imp_data_files = [join(imp_data_folder, f) for f in listdir(imp_data_folder) if isfile(join(imp_data_folder, f))]\n",
    "\n",
    "test_data.to_csv(test_data_file, index=False, na_rep=\"\\\\N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i num_imp,imp_data_folder,test_data_file -o imp_data_files\n",
    "\n",
    "# Imputation in R using MICE\n",
    "library(mice)\n",
    "\n",
    "random_seed <- 151\n",
    "set.seed(random_seed)\n",
    "\n",
    "src_data <- read.table(test_data_file, sep=\",\", header=TRUE, na.strings=\"\\\\N\")\n",
    "\n",
    "imp_data <- mice(src_data, meth='pmm', m=num_imp)\n",
    "var_drop <- c(\".imp\", \".id\")\n",
    "imp_data_files <- character(0)\n",
    "for (iter in 1:num_imp) {\n",
    "    comp_data <- complete(imp_data, action=iter)  \n",
    "    comp_data <- comp_data[,!(names(comp_data) %in% var_drop)]\n",
    "    fn <- paste(imp_data_folder, \"/imputation-\", iter, \".csv\", sep=\"\")\n",
    "    write.csv(comp_data, file=fn, row.names=FALSE)\n",
    "    imp_data_files <- c(imp_data_files, fn)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases : 106\n",
      "Mean CFR        : 74.00\n",
      "\n",
      "Measures of performance\n",
      "AUC           : 0.78 (0.04)\n",
      "Brier         : 0.19 (0.01)\n",
      "Accuracy      : 0.73 (0.03)\n",
      "Sensitivity   : 0.73 (0.03)\n",
      "Specificity   : 0.88 (0.03)\n"
     ]
    }
   ],
   "source": [
    "ytrue_all = []\n",
    "probs_all = []\n",
    "\n",
    "cfr_list = []\n",
    "auc_list = [] \n",
    "brier_list = [] \n",
    "cal_list = [] \n",
    "dis_list = [] \n",
    "acc_list = []\n",
    "prec0_list = [] \n",
    "prec1_list = [] \n",
    "rec0_list = [] \n",
    "rec1_list = []\n",
    "f10_list = [] \n",
    "f11_list = []  \n",
    "\n",
    "for fn in imp_data_files:\n",
    "    data = pd.read_csv(fn)\n",
    "\n",
    "    x = data[data.columns[1:]].values\n",
    "    ytrue = [int(v) for v in data[data.columns[0]].values]\n",
    "    probs = list(model.predict(x))\n",
    "    \n",
    "    ypred = [int(0.5 < p) for p in probs]\n",
    "    cfr = float(np.sum(ytrue)) / len(ytrue)\n",
    "    \n",
    "    ytrue_all += ytrue\n",
    "    probs_all += probs\n",
    "    \n",
    "    auc = roc_auc_score(ytrue, probs)\n",
    "    brier = brier_score_loss(ytrue, probs)\n",
    "    cal, dis = caldis(ytrue, probs)\n",
    "    acc = accuracy_score(ytrue, ypred)\n",
    "    precision, recall, f1score, support = precision_recall_fscore_support(ytrue, ypred)\n",
    "    \n",
    "    cfr_list.append(cfr)\n",
    "    auc_list.append(auc)\n",
    "    brier_list.append(brier)\n",
    "    cal_list.append(cal)\n",
    "    dis_list.append(dis)\n",
    "    acc_list.append(acc)\n",
    "    prec0_list.append(precision[0])\n",
    "    prec1_list.append(precision[1])\n",
    "    rec0_list.append(recall[0])\n",
    "    rec1_list.append(recall[1])\n",
    "    f10_list.append(f1score[0])\n",
    "    f11_list.append(f1score[1])  \n",
    "\n",
    "cfr_mean = np.mean(cfr_list)\n",
    "auc_mean = np.mean(auc_list)\n",
    "brier_mean = np.mean(brier_list)\n",
    "cal_mean = np.mean(cal_list)\n",
    "dis_mean = np.mean(dis_list)      \n",
    "acc_mean = np.mean(acc_list)\n",
    "prec0_mean = np.mean(prec0_list)\n",
    "prec1_mean = np.mean(prec1_list)\n",
    "rec0_mean = np.mean(rec0_list)\n",
    "rec1_mean = np.mean(rec1_list)\n",
    "f10_mean = np.mean(f10_list)\n",
    "f11_mean = np.mean(f11_list)\n",
    " \n",
    "cfr_dev = np.std(cfr_list)\n",
    "auc_dev = np.std(auc_list)\n",
    "brier_dev = np.std(brier_list)\n",
    "cal_dev = np.std(cal_list)\n",
    "dis_dev = np.std(dis_list)      \n",
    "acc_dev = np.std(acc_list)\n",
    "prec0_dev = np.std(prec0_list)\n",
    "prec1_dev = np.std(prec1_list)\n",
    "rec0_dev = np.std(rec0_list)\n",
    "rec1_dev = np.std(rec1_list)\n",
    "f10_dev = np.std(f10_list)\n",
    "f11_dev = np.std(f11_list)    \n",
    "    \n",
    "print(\"Number of cases :\", len(ytrue))\n",
    "print(\"Mean CFR        : %0.2f\" % (100 * cfr_mean))\n",
    "print(\"\")\n",
    "print(\"Measures of performance\")\n",
    "print(\"AUC           : %0.2f (%0.2f)\" % (auc_mean, auc_dev))\n",
    "print(\"Brier         : %0.2f (%0.2f)\" % (brier_mean, brier_dev))\n",
    "# print(\"Calibration   :\", cal_mean, '+/-', cal_dev)\n",
    "# print(\"Discrimination:\", dis_mean, '+/-', dis_dev)\n",
    "print(\"Accuracy      : %0.2f (%0.2f)\" % (acc_mean, acc_dev))\n",
    "print(\"Sensitivity   : %0.2f (%0.2f)\" % (rec1_mean, rec1_dev))\n",
    "print(\"Specificity   : %0.2f (%0.2f)\" % (prec1_mean, prec1_dev))\n",
    "\n",
    "# print(\"Precision (live)  :\", prec0_mean, '+/-', prec0_dev,\" (specificity for die)\")\n",
    "# print(\"Precision (die)   :\", prec1_mean, '+/-', prec1_dev,\" (specificity for live)\") \n",
    "# print(\"Sensitivity (live):\", rec0_mean, '+/-', rec0_dev) \n",
    "# print(\"Sensitivity (die) :\", rec1_mean, '+/-', rec1_dev) \n",
    "\n",
    "with open(os.path.join(model_name, 'kenema-validation-imp.txt'), 'w') as of:\n",
    "    of.write(\"Measures of performance\\n\")\n",
    "    of.write(\"AUC           : %0.2f (%0.2f)\\n\" % (auc_mean, auc_dev))\n",
    "    of.write(\"Brier         : %0.2f (%0.2f)\\n\" % (brier_mean, brier_dev))\n",
    "#     of.write(\"Calibration   : \" + str(cal_mean) + \"+/-\" + str(cal_dev) + \"\\n\")\n",
    "#     of.write(\"Discrimination: \" + str(dis_mean) + \"+/-\" + str(dis_dev) + \"\\n\")\n",
    "    of.write(\"Accuracy      : %0.2f (%0.2f)\\n\" % (acc_mean, acc_dev))\n",
    "    of.write(\"Sensitivity   : %0.2f (%0.2f)\\n\" % (rec1_mean, rec1_dev))    \n",
    "    of.write(\"Specificity   : %0.2f (%0.2f)\\n\" % (prec1_mean, prec1_dev))    \n",
    "    \n",
    "#     of.write(\"Precision (live)  : \" + str(prec0_mean) + \"+/-\" + str(prec0_dev) + \" (specificity for die)\\n\")\n",
    "#     of.write(\"Precision (die)   : \" + str(prec1_mean) + \"+/-\" + str(prec1_dev) + \" (specificity for live)\\n\")\n",
    "#     of.write(\"Sensitivity (live): \" + str(rec0_mean) + \"+/-\" + str(rec0_dev) + \"\\n\")\n",
    "#     of.write(\"Sensitivity (die) : \" + str(rec1_mean) + \"+/-\" + str(rec1_dev) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
